{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fa7f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>ID</th>\n",
       "      <th>weird_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Colorado Senate Primary: John Hickenlooper Fa...</td>\n",
       "      <td>31930103</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>US</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>https://www.npr.org/2020/06/28/883922991/one-o...</td>\n",
       "      <td>Colorado Senate Primary: John Hickenlooper Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>SACRAMENTO -- Public access to police discipl...</td>\n",
       "      <td>31930303</td>\n",
       "      <td>775.0</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>US</td>\n",
       "      <td>mercurynews.com</td>\n",
       "      <td>https://www.mercurynews.com/2020/06/29/bill-wo...</td>\n",
       "      <td>Bill would broaden and speed up access to Cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Dolores Attea Sapienza, 88, queen of special ...</td>\n",
       "      <td>31930400</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>US</td>\n",
       "      <td>buffalonews.com</td>\n",
       "      <td>https://buffalonews.com/news/local/dolores-att...</td>\n",
       "      <td>Dolores Attea Sapienza, 88, queen of special e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>Roswell Park plans expansion of cancer care i...</td>\n",
       "      <td>31930401</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>US</td>\n",
       "      <td>buffalonews.com</td>\n",
       "      <td>https://buffalonews.com/news/local/roswell-par...</td>\n",
       "      <td>Roswell Park plans expansion of cancer care in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Subscribers to The Climate Crisis newsletter ...</td>\n",
       "      <td>31930409</td>\n",
       "      <td>2318.0</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>US</td>\n",
       "      <td>newyorker.com</td>\n",
       "      <td>https://www.newyorker.com/news/annals-of-a-war...</td>\n",
       "      <td>At the Core of the Climate Crisis | The New Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41724</th>\n",
       "      <td>450142</td>\n",
       "      <td>Colorado Rockies shortstop Ian Desmond became...</td>\n",
       "      <td>85307989</td>\n",
       "      <td>403.0</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>UPI.com</td>\n",
       "      <td>https://www.upi.com/Sports_News/MLB/2020/06/30...</td>\n",
       "      <td>All-Star SS Ian Desmond to skip MLB season, ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41725</th>\n",
       "      <td>450144</td>\n",
       "      <td>\" I have very, very strict standards about me...</td>\n",
       "      <td>85307991</td>\n",
       "      <td>443.0</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Us Weekly</td>\n",
       "      <td>https://www.usmagazine.com/celebrity-moms/news...</td>\n",
       "      <td>Why Phaedra Parks Hasn't Introduced Her 2 Kids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41726</th>\n",
       "      <td>450153</td>\n",
       "      <td>Comedy legend Carl Reiner, one of the earlies...</td>\n",
       "      <td>85308187</td>\n",
       "      <td>980.0</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>NBC News</td>\n",
       "      <td>https://www.nbcnews.com/news/us-news/comedy-le...</td>\n",
       "      <td>Comedy legend Carl Reiner, of 'The Dick Van Dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41727</th>\n",
       "      <td>450185</td>\n",
       "      <td>Jon Stewart and Rose Byrne want' Irresistible...</td>\n",
       "      <td>85308688</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>Houston Chronicle</td>\n",
       "      <td>https://www.chron.com/entertainment/article/Jo...</td>\n",
       "      <td>Jon Stewart and Rose Byrne want 'Irresistible'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>450213</td>\n",
       "      <td>The second quarter of this year was a kind on...</td>\n",
       "      <td>85309194</td>\n",
       "      <td>289.0</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>US</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>https://www.yahoo.com/entertainment/cable-news...</td>\n",
       "      <td>Cable News Networks Show Quarterly Gains, `Tuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41729 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               text        ID  \\\n",
       "0           3   Colorado Senate Primary: John Hickenlooper Fa...  31930103   \n",
       "1          13   SACRAMENTO -- Public access to police discipl...  31930303   \n",
       "2          18   Dolores Attea Sapienza, 88, queen of special ...  31930400   \n",
       "3          19   Roswell Park plans expansion of cancer care i...  31930401   \n",
       "4          25   Subscribers to The Climate Crisis newsletter ...  31930409   \n",
       "...       ...                                                ...       ...   \n",
       "41724  450142   Colorado Rockies shortstop Ian Desmond became...  85307989   \n",
       "41725  450144   \" I have very, very strict standards about me...  85307991   \n",
       "41726  450153   Comedy legend Carl Reiner, one of the earlies...  85308187   \n",
       "41727  450185   Jon Stewart and Rose Byrne want' Irresistible...  85308688   \n",
       "41728  450213   The second quarter of this year was a kind on...  85309194   \n",
       "\n",
       "       weird_id      Date Country   News_source_name  \\\n",
       "0        1492.0  20-07-01      US            npr.org   \n",
       "1         775.0  20-07-01      US    mercurynews.com   \n",
       "2        1056.0  20-07-01      US    buffalonews.com   \n",
       "3        1014.0  20-07-01      US    buffalonews.com   \n",
       "4        2318.0  20-07-01      US      newyorker.com   \n",
       "...         ...       ...     ...                ...   \n",
       "41724     403.0  20-06-30      US            UPI.com   \n",
       "41725     443.0  20-06-30      US          Us Weekly   \n",
       "41726     980.0  20-06-30      US           NBC News   \n",
       "41727    1086.0  20-06-30      US  Houston Chronicle   \n",
       "41728     289.0  20-06-30      US             YAHOO!   \n",
       "\n",
       "                                                    link  \\\n",
       "0      https://www.npr.org/2020/06/28/883922991/one-o...   \n",
       "1      https://www.mercurynews.com/2020/06/29/bill-wo...   \n",
       "2      https://buffalonews.com/news/local/dolores-att...   \n",
       "3      https://buffalonews.com/news/local/roswell-par...   \n",
       "4      https://www.newyorker.com/news/annals-of-a-war...   \n",
       "...                                                  ...   \n",
       "41724  https://www.upi.com/Sports_News/MLB/2020/06/30...   \n",
       "41725  https://www.usmagazine.com/celebrity-moms/news...   \n",
       "41726  https://www.nbcnews.com/news/us-news/comedy-le...   \n",
       "41727  https://www.chron.com/entertainment/article/Jo...   \n",
       "41728  https://www.yahoo.com/entertainment/cable-news...   \n",
       "\n",
       "                                                   title  \n",
       "0      Colorado Senate Primary: John Hickenlooper Fac...  \n",
       "1      Bill would broaden and speed up access to Cali...  \n",
       "2      Dolores Attea Sapienza, 88, queen of special e...  \n",
       "3      Roswell Park plans expansion of cancer care in...  \n",
       "4      At the Core of the Climate Crisis | The New Yo...  \n",
       "...                                                  ...  \n",
       "41724  All-Star SS Ian Desmond to skip MLB season, ci...  \n",
       "41725  Why Phaedra Parks Hasn't Introduced Her 2 Kids...  \n",
       "41726  Comedy legend Carl Reiner, of 'The Dick Van Dy...  \n",
       "41727  Jon Stewart and Rose Byrne want 'Irresistible'...  \n",
       "41728  Cable News Networks Show Quarterly Gains, `Tuc...  \n",
       "\n",
       "[41729 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "term_list_df = pd.read_csv(\"data/NOW_preprocessed/BLM_filtered_preprocessed_news_sources_df.csv\")\n",
    "print(len(term_list_df))\n",
    "\n",
    "content = term_list_df[\"text\"][0]\n",
    "\n",
    "term_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90731297",
   "metadata": {},
   "source": [
    "## SV extraction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad9ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### applying SV extractor (self made from prev. trial 18 versions)\n",
    "# it is based on the textpipliner package: https://github.com/krzysiekfonal/textpipeliner\n",
    "# decoding of pipes: https://github.com/krzysiekfonal/grammaregex\n",
    "# decoding of POS: https://www.guru99.com/pos-tagging-chunking-nltk.html\n",
    "\n",
    "# adding additional named entity filters to pipe structure\n",
    "# list of filters: https://stackoverflow.com/questions/59319207/ner-entity-recognition-country-filter\n",
    "\n",
    "from textpipeliner import PipelineEngine, Context\n",
    "from textpipeliner.pipes import *\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(content)\n",
    "\n",
    "def SV_extractor(content):\n",
    "    doc = nlp(content)\n",
    "    pipes_structure = [\n",
    "        AnyPipe([\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/nsubj/*\"),\n",
    "                AggregatePipe([\n",
    "                    NamedEntityFilterPipe(\"PERSON\"),\n",
    "                    NamedEntityFilterPipe(\"FAC\"),\n",
    "                    NamedEntityFilterPipe(\"LOC\"),\n",
    "                    NamedEntityFilterPipe(\"GPE\"),\n",
    "                    NamedEntityFilterPipe(\"PRODUCT\"),\n",
    "                    NamedEntityFilterPipe(\"LAW\"),\n",
    "                    NamedEntityFilterPipe(\"LANGUAGE\"),\n",
    "                    NamedEntityFilterPipe(\"DATE\"),\n",
    "                    NamedEntityFilterPipe(\"TIME\"),\n",
    "                    NamedEntityFilterPipe(\"PERCENT\"),\n",
    "                    NamedEntityFilterPipe(\"MONEY\"),\n",
    "                    NamedEntityFilterPipe(\"QUANTITY\"),\n",
    "                    NamedEntityFilterPipe(\"ORDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"CARDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"ORG\"),\n",
    "                    NamedEntityFilterPipe(\"WORK_OF_ART\"),\n",
    "                    NamedEntityFilterPipe(\"EVENT\")\n",
    "                    ]),\n",
    "                NamedEntityExtractorPipe()]),\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/agent/*/pobj/*\"),\n",
    "                AggregatePipe([\n",
    "                    NamedEntityFilterPipe(\"PERSON\"),\n",
    "                    NamedEntityFilterPipe(\"FAC\"),\n",
    "                    NamedEntityFilterPipe(\"LOC\"),\n",
    "                    NamedEntityFilterPipe(\"GPE\"),\n",
    "                    NamedEntityFilterPipe(\"PRODUCT\"),\n",
    "                    NamedEntityFilterPipe(\"LAW\"),\n",
    "                    NamedEntityFilterPipe(\"LANGUAGE\"),\n",
    "                    NamedEntityFilterPipe(\"DATE\"),\n",
    "                    NamedEntityFilterPipe(\"TIME\"),\n",
    "                    NamedEntityFilterPipe(\"PERCENT\"),\n",
    "                    NamedEntityFilterPipe(\"MONEY\"),\n",
    "                    NamedEntityFilterPipe(\"QUANTITY\"),\n",
    "                    NamedEntityFilterPipe(\"ORDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"CARDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"ORG\"),\n",
    "                    NamedEntityFilterPipe(\"WORK_OF_ART\"),\n",
    "                    NamedEntityFilterPipe(\"EVENT\")\n",
    "                    ]),\n",
    "                NamedEntityExtractorPipe()]),\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/nsubj/*\")]),\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/agent/*/pobj/*\")])]),\n",
    "        FindTokensPipe(\"VERB\")\n",
    "    ]\n",
    "    engine = PipelineEngine(pipes_structure, Context(doc), [0, 1])\n",
    "    SVs = engine.process()\n",
    "    return SVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff72f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the SV_extractor function on each row of my pandas dataframe\n",
    "\n",
    "term_list_df[\"SVs\"] = term_list_df.apply(lambda row: SV_extractor(row[\"text\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc132298",
   "metadata": {},
   "outputs": [],
   "source": [
    "SV_df = term_list_df[[\"ID\", \"Date\", \"News_source_name\", \"SVs\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16794059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>SVs</th>\n",
       "      <th>S</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([1], [Stumbles])</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[Stumbles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([Getty, Images], [hide])</td>\n",
       "      <td>[Getty, Images]</td>\n",
       "      <td>[hide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([voters], [decide])</td>\n",
       "      <td>[voters]</td>\n",
       "      <td>[decide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([voters], [pick])</td>\n",
       "      <td>[voters]</td>\n",
       "      <td>[pick]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([Romanoff], [run])</td>\n",
       "      <td>[Romanoff]</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([MSNBC], [came])</td>\n",
       "      <td>[MSNBC]</td>\n",
       "      <td>[came]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([FNC], [averaged])</td>\n",
       "      <td>[FNC]</td>\n",
       "      <td>[averaged]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([MSNBC], [came])</td>\n",
       "      <td>[MSNBC]</td>\n",
       "      <td>[came]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([show], [drew])</td>\n",
       "      <td>[show]</td>\n",
       "      <td>[drew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([CNN], [won])</td>\n",
       "      <td>[CNN]</td>\n",
       "      <td>[won]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1085437 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Date News_source_name                        SVs  \\\n",
       "0      31930103  20-07-01          npr.org          ([1], [Stumbles])   \n",
       "0      31930103  20-07-01          npr.org  ([Getty, Images], [hide])   \n",
       "0      31930103  20-07-01          npr.org       ([voters], [decide])   \n",
       "0      31930103  20-07-01          npr.org         ([voters], [pick])   \n",
       "0      31930103  20-07-01          npr.org        ([Romanoff], [run])   \n",
       "...         ...       ...              ...                        ...   \n",
       "41728  85309194  20-06-30           YAHOO!          ([MSNBC], [came])   \n",
       "41728  85309194  20-06-30           YAHOO!        ([FNC], [averaged])   \n",
       "41728  85309194  20-06-30           YAHOO!          ([MSNBC], [came])   \n",
       "41728  85309194  20-06-30           YAHOO!           ([show], [drew])   \n",
       "41728  85309194  20-06-30           YAHOO!             ([CNN], [won])   \n",
       "\n",
       "                     S           V  \n",
       "0                  [1]  [Stumbles]  \n",
       "0      [Getty, Images]      [hide]  \n",
       "0             [voters]    [decide]  \n",
       "0             [voters]      [pick]  \n",
       "0           [Romanoff]       [run]  \n",
       "...                ...         ...  \n",
       "41728          [MSNBC]      [came]  \n",
       "41728            [FNC]  [averaged]  \n",
       "41728          [MSNBC]      [came]  \n",
       "41728           [show]      [drew]  \n",
       "41728            [CNN]       [won]  \n",
       "\n",
       "[1085437 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within the dataframe, separating the list of SV pairs into individual SV pairs per row\n",
    "\n",
    "SV_df_exploded = SV_df.explode(\"SVs\")\n",
    "\n",
    "SV_df_exploded[[\"S\", \"V\"]] = pd.DataFrame(SV_df_exploded.SVs.tolist(), index = SV_df_exploded.index)\n",
    "\n",
    "SV_df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce0e7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving df with VO triples into a csv file\n",
    "\n",
    "SV_df_exploded.to_csv(\"data/NOW_preprocessed/total_SV_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660d418",
   "metadata": {},
   "source": [
    "## VO extraction ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27fbd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### applying VO extractor (self made from prev. trial 18 versions)\n",
    "# it is based on the textpipliner package: https://github.com/krzysiekfonal/textpipeliner\n",
    "# decoding of pipes: https://github.com/krzysiekfonal/grammaregex\n",
    "# decoding of POS: https://www.guru99.com/pos-tagging-chunking-nltk.html\n",
    "\n",
    "# adding additional named entity filters to pipe structure\n",
    "# list of filters: https://stackoverflow.com/questions/59319207/ner-entity-recognition-country-filter\n",
    "\n",
    "from textpipeliner import PipelineEngine, Context\n",
    "from textpipeliner.pipes import *\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(content)\n",
    "\n",
    "def VO_extractor(content):\n",
    "    doc = nlp(content)\n",
    "    pipes_structure = [\n",
    "        FindTokensPipe(\"VERB\"),\n",
    "        AnyPipe([    \n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/dobj/*\"),\n",
    "                AggregatePipe([\n",
    "                    NamedEntityFilterPipe(\"PERSON\"),\n",
    "                    NamedEntityFilterPipe(\"FAC\"),\n",
    "                    NamedEntityFilterPipe(\"LOC\"),\n",
    "                    NamedEntityFilterPipe(\"GPE\"),\n",
    "                    NamedEntityFilterPipe(\"PRODUCT\"),\n",
    "                    NamedEntityFilterPipe(\"LAW\"),\n",
    "                    NamedEntityFilterPipe(\"LANGUAGE\"),\n",
    "                    NamedEntityFilterPipe(\"DATE\"),\n",
    "                    NamedEntityFilterPipe(\"TIME\"),\n",
    "                    NamedEntityFilterPipe(\"PERCENT\"),\n",
    "                    NamedEntityFilterPipe(\"MONEY\"),\n",
    "                    NamedEntityFilterPipe(\"QUANTITY\"),\n",
    "                    NamedEntityFilterPipe(\"ORDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"CARDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"ORG\"),\n",
    "                    NamedEntityFilterPipe(\"WORK_OF_ART\"),\n",
    "                    NamedEntityFilterPipe(\"EVENT\")\n",
    "                    ]),\n",
    "                NamedEntityExtractorPipe()]),\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/nsubjpass/*\"),\n",
    "                AggregatePipe([\n",
    "                    NamedEntityFilterPipe(\"PERSON\"),\n",
    "                    NamedEntityFilterPipe(\"FAC\"),\n",
    "                    NamedEntityFilterPipe(\"LOC\"),\n",
    "                    NamedEntityFilterPipe(\"GPE\"),\n",
    "                    NamedEntityFilterPipe(\"PRODUCT\"),\n",
    "                    NamedEntityFilterPipe(\"LAW\"),\n",
    "                    NamedEntityFilterPipe(\"LANGUAGE\"),\n",
    "                    NamedEntityFilterPipe(\"DATE\"),\n",
    "                    NamedEntityFilterPipe(\"TIME\"),\n",
    "                    NamedEntityFilterPipe(\"PERCENT\"),\n",
    "                    NamedEntityFilterPipe(\"MONEY\"),\n",
    "                    NamedEntityFilterPipe(\"QUANTITY\"),\n",
    "                    NamedEntityFilterPipe(\"ORDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"CARDINAL\"),\n",
    "                    NamedEntityFilterPipe(\"ORG\"),\n",
    "                    NamedEntityFilterPipe(\"WORK_OF_ART\"),\n",
    "                    NamedEntityFilterPipe(\"EVENT\")\n",
    "                    ]),\n",
    "                NamedEntityExtractorPipe()]),\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/dobj/*\")]),\n",
    "            SequencePipe([\n",
    "                FindTokensPipe(\"VERB/nsubjpass/*\")])])\n",
    "            ]\n",
    "    engine = PipelineEngine(pipes_structure, Context(doc), [0, 1])\n",
    "    VOs = engine.process()\n",
    "    return VOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7f7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the VO_extractor function on each row of my pandas dataframe\n",
    "\n",
    "term_list_df[\"VOs\"] = term_list_df.apply(lambda row: VO_extractor(row[\"text\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da6a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VO_df = term_list_df[[\"ID\", \"Date\", \"News_source_name\", \"VOs\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5699a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>VOs</th>\n",
       "      <th>V</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([seen], [[John, Hickenlooper], [Colorado, Sen...</td>\n",
       "      <td>[seen]</td>\n",
       "      <td>[[John, Hickenlooper], [Colorado, Senate, Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([made], [missteps])</td>\n",
       "      <td>[made]</td>\n",
       "      <td>[missteps]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([hide], [caption])</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[caption]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([considered], [John, Hickenlooper])</td>\n",
       "      <td>[considered]</td>\n",
       "      <td>[John, Hickenlooper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([made], [missteps])</td>\n",
       "      <td>[made]</td>\n",
       "      <td>[missteps]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([posted], [gains])</td>\n",
       "      <td>[posted]</td>\n",
       "      <td>[gains]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([led], [way])</td>\n",
       "      <td>[led]</td>\n",
       "      <td>[way]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([averaged], [viewers])</td>\n",
       "      <td>[averaged]</td>\n",
       "      <td>[viewers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([drew], [viewers])</td>\n",
       "      <td>[drew]</td>\n",
       "      <td>[viewers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([won], [crown])</td>\n",
       "      <td>[won]</td>\n",
       "      <td>[crown]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570373 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Date News_source_name  \\\n",
       "0      31930103  20-07-01          npr.org   \n",
       "0      31930103  20-07-01          npr.org   \n",
       "0      31930103  20-07-01          npr.org   \n",
       "0      31930103  20-07-01          npr.org   \n",
       "0      31930103  20-07-01          npr.org   \n",
       "...         ...       ...              ...   \n",
       "41728  85309194  20-06-30           YAHOO!   \n",
       "41728  85309194  20-06-30           YAHOO!   \n",
       "41728  85309194  20-06-30           YAHOO!   \n",
       "41728  85309194  20-06-30           YAHOO!   \n",
       "41728  85309194  20-06-30           YAHOO!   \n",
       "\n",
       "                                                     VOs             V  \\\n",
       "0      ([seen], [[John, Hickenlooper], [Colorado, Sen...        [seen]   \n",
       "0                                   ([made], [missteps])        [made]   \n",
       "0                                    ([hide], [caption])        [hide]   \n",
       "0                   ([considered], [John, Hickenlooper])  [considered]   \n",
       "0                                   ([made], [missteps])        [made]   \n",
       "...                                                  ...           ...   \n",
       "41728                                ([posted], [gains])      [posted]   \n",
       "41728                                     ([led], [way])         [led]   \n",
       "41728                            ([averaged], [viewers])    [averaged]   \n",
       "41728                                ([drew], [viewers])        [drew]   \n",
       "41728                                   ([won], [crown])         [won]   \n",
       "\n",
       "                                                       O  \n",
       "0      [[John, Hickenlooper], [Colorado, Senate, Prim...  \n",
       "0                                             [missteps]  \n",
       "0                                              [caption]  \n",
       "0                                   [John, Hickenlooper]  \n",
       "0                                             [missteps]  \n",
       "...                                                  ...  \n",
       "41728                                            [gains]  \n",
       "41728                                              [way]  \n",
       "41728                                          [viewers]  \n",
       "41728                                          [viewers]  \n",
       "41728                                            [crown]  \n",
       "\n",
       "[570373 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within the dataframe, separating the list of VO pairs into individual VO pairs per row\n",
    "\n",
    "VO_df_exploded = VO_df.explode(\"VOs\")\n",
    "\n",
    "VO_df_exploded[[\"V\", \"O\"]] = pd.DataFrame(VO_df_exploded.VOs.tolist(), index = VO_df_exploded.index)\n",
    "\n",
    "VO_df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b9e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving df with VO triples into a csv file\n",
    "\n",
    "VO_df_exploded.to_csv(\"data/NOW_preprocessed/total_VO_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ce96b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
