{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00eb2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085437\n",
      "570373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SV_df = pd.read_csv(\"data/NOW_preprocessed/total_SV_df.csv\")\n",
    "VO_df = pd.read_csv(\"data/NOW_preprocessed/total_VO_df.csv\")\n",
    "\n",
    "print(len(SV_df))\n",
    "print(len(VO_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debcfc53",
   "metadata": {},
   "source": [
    "## Bringing SV, VO columns to a preprocessed format ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f765bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "202\n",
      "0\n",
      "0\n",
      "1085430\n",
      "570171\n"
     ]
    }
   ],
   "source": [
    "# checking how many NAs there are\n",
    "\n",
    "print(SV_df['SVs'].isna().sum()) \n",
    "print(VO_df['VOs'].isna().sum())\n",
    "\n",
    "# removing the NAs\n",
    "\n",
    "SV_df_nona = SV_df[SV_df['SVs'].notna()]\n",
    "VO_df_nona = VO_df[VO_df['VOs'].notna()]\n",
    "\n",
    "\n",
    "print(SV_df_nona['SVs'].isna().sum()) \n",
    "print(VO_df_nona['VOs'].isna().sum())\n",
    "\n",
    "print(len(SV_df_nona))\n",
    "print(len(VO_df_nona))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c9171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-252833377575>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona['S_string'] = SV_df_nona['S'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-3-252833377575>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona['S_string'] = SV_df_nona.apply(lambda row: text_cleaner(row[\"S_string\"]), axis = 1)\n",
      "<ipython-input-3-252833377575>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona['V_string'] = SV_df_nona['V'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-3-252833377575>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona['V_string'] = VO_df_nona['V'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-3-252833377575>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona['O_string'] = VO_df_nona['O'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-3-252833377575>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona['O_string'] = VO_df_nona.apply(lambda row: text_cleaner(row[\"O_string\"]), axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>VOs</th>\n",
       "      <th>V</th>\n",
       "      <th>O</th>\n",
       "      <th>V_string</th>\n",
       "      <th>O_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([seen], [[John, Hickenlooper], [Colorado, Sen...</td>\n",
       "      <td>[seen]</td>\n",
       "      <td>[[John, Hickenlooper], [Colorado, Senate, Prim...</td>\n",
       "      <td>seen</td>\n",
       "      <td>[John Hickenlooper] [Colorado Senate Primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([made], [missteps])</td>\n",
       "      <td>[made]</td>\n",
       "      <td>[missteps]</td>\n",
       "      <td>made</td>\n",
       "      <td>missteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([hide], [caption])</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[caption]</td>\n",
       "      <td>hide</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([considered], [John, Hickenlooper])</td>\n",
       "      <td>[considered]</td>\n",
       "      <td>[John, Hickenlooper]</td>\n",
       "      <td>considered</td>\n",
       "      <td>John Hickenlooper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([made], [missteps])</td>\n",
       "      <td>[made]</td>\n",
       "      <td>[missteps]</td>\n",
       "      <td>made</td>\n",
       "      <td>missteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570368</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([posted], [gains])</td>\n",
       "      <td>[posted]</td>\n",
       "      <td>[gains]</td>\n",
       "      <td>posted</td>\n",
       "      <td>gains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570369</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([led], [way])</td>\n",
       "      <td>[led]</td>\n",
       "      <td>[way]</td>\n",
       "      <td>led</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570370</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([averaged], [viewers])</td>\n",
       "      <td>[averaged]</td>\n",
       "      <td>[viewers]</td>\n",
       "      <td>averaged</td>\n",
       "      <td>viewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570371</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([drew], [viewers])</td>\n",
       "      <td>[drew]</td>\n",
       "      <td>[viewers]</td>\n",
       "      <td>drew</td>\n",
       "      <td>viewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570372</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([won], [crown])</td>\n",
       "      <td>[won]</td>\n",
       "      <td>[crown]</td>\n",
       "      <td>won</td>\n",
       "      <td>crown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570171 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID      Date News_source_name  \\\n",
       "0       31930103  20-07-01          npr.org   \n",
       "1       31930103  20-07-01          npr.org   \n",
       "2       31930103  20-07-01          npr.org   \n",
       "3       31930103  20-07-01          npr.org   \n",
       "4       31930103  20-07-01          npr.org   \n",
       "...          ...       ...              ...   \n",
       "570368  85309194  20-06-30           YAHOO!   \n",
       "570369  85309194  20-06-30           YAHOO!   \n",
       "570370  85309194  20-06-30           YAHOO!   \n",
       "570371  85309194  20-06-30           YAHOO!   \n",
       "570372  85309194  20-06-30           YAHOO!   \n",
       "\n",
       "                                                      VOs             V  \\\n",
       "0       ([seen], [[John, Hickenlooper], [Colorado, Sen...        [seen]   \n",
       "1                                    ([made], [missteps])        [made]   \n",
       "2                                     ([hide], [caption])        [hide]   \n",
       "3                    ([considered], [John, Hickenlooper])  [considered]   \n",
       "4                                    ([made], [missteps])        [made]   \n",
       "...                                                   ...           ...   \n",
       "570368                                ([posted], [gains])      [posted]   \n",
       "570369                                     ([led], [way])         [led]   \n",
       "570370                            ([averaged], [viewers])    [averaged]   \n",
       "570371                                ([drew], [viewers])        [drew]   \n",
       "570372                                   ([won], [crown])         [won]   \n",
       "\n",
       "                                                        O    V_string  \\\n",
       "0       [[John, Hickenlooper], [Colorado, Senate, Prim...        seen   \n",
       "1                                              [missteps]        made   \n",
       "2                                               [caption]        hide   \n",
       "3                                    [John, Hickenlooper]  considered   \n",
       "4                                              [missteps]        made   \n",
       "...                                                   ...         ...   \n",
       "570368                                            [gains]      posted   \n",
       "570369                                              [way]         led   \n",
       "570370                                          [viewers]    averaged   \n",
       "570371                                          [viewers]        drew   \n",
       "570372                                            [crown]         won   \n",
       "\n",
       "                                             O_string  \n",
       "0       [John Hickenlooper] [Colorado Senate Primary]  \n",
       "1                                            missteps  \n",
       "2                                             caption  \n",
       "3                                   John Hickenlooper  \n",
       "4                                            missteps  \n",
       "...                                               ...  \n",
       "570368                                          gains  \n",
       "570369                                            way  \n",
       "570370                                        viewers  \n",
       "570371                                        viewers  \n",
       "570372                                          crown  \n",
       "\n",
       "[570171 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking the S, V, O columns out of list format, making it into string:\n",
    "\n",
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text_cleaned = re.sub(r\",\", \"\", text) \n",
    "    return text_cleaned\n",
    "\n",
    "\n",
    "# making the list column into string on the SV df\n",
    "\n",
    "SV_df_nona['S_string'] = SV_df_nona['S'].apply(lambda x: x[1:-1])\n",
    "SV_df_nona['S_string'] = SV_df_nona.apply(lambda row: text_cleaner(row[\"S_string\"]), axis = 1)\n",
    "SV_df_nona['V_string'] = SV_df_nona['V'].apply(lambda x: x[1:-1])\n",
    "\n",
    "SV_df_nona\n",
    "\n",
    "\n",
    "# making the list column into string on the VO df\n",
    "\n",
    "VO_df_nona['V_string'] = VO_df_nona['V'].apply(lambda x: x[1:-1])\n",
    "VO_df_nona['O_string'] = VO_df_nona['O'].apply(lambda x: x[1:-1])\n",
    "VO_df_nona['O_string'] = VO_df_nona.apply(lambda row: text_cleaner(row[\"O_string\"]), axis = 1)\n",
    "\n",
    "VO_df_nona\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f301bc4",
   "metadata": {},
   "source": [
    "### filtering for S and O that includes BLM relevant terms. Worthy revisions: extend term list, save to csv. #### Important to note: if term list fitlers are changed, the news sources have to be reassessed. Additional news sources might be inlcuded in the exported csv files, which have to be checked for bias ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d483692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c8b61c8aee2c>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_breonna_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_floyd_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_trayvon_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_movement_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_blacklivesmatter_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_blm_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_protester_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_demonstrator_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_nationalguard_S[\"Side\"] = \"1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_bluelivesmatter_S[\"Side\"] = \"1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_police_S[\"Side\"] = \"1\"\n",
      "<ipython-input-4-c8b61c8aee2c>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_government_S[\"Side\"] = \"1\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>SVs</th>\n",
       "      <th>S</th>\n",
       "      <th>V</th>\n",
       "      <th>S_string</th>\n",
       "      <th>V_string</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85330111</td>\n",
       "      <td>20-07-03</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>([Breonna, Taylor], [sleeping])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[sleeping]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85395800</td>\n",
       "      <td>20-07-11</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([Breonna, Taylor], [used])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[used]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>used</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85543408</td>\n",
       "      <td>20-07-30</td>\n",
       "      <td>NBC News</td>\n",
       "      <td>([Breonna, Taylor], [cover])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[cover]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>cover</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85068543</td>\n",
       "      <td>20-06-01</td>\n",
       "      <td>Milwaukee Journal Sentinel</td>\n",
       "      <td>([Breonna, Taylor], [wanted])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[wanted]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>wanted</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85101644</td>\n",
       "      <td>20-06-05</td>\n",
       "      <td>E News</td>\n",
       "      <td>([Breonna], [celebrating])</td>\n",
       "      <td>[Breonna]</td>\n",
       "      <td>[celebrating]</td>\n",
       "      <td>Breonna</td>\n",
       "      <td>celebrating</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34440</th>\n",
       "      <td>85288194</td>\n",
       "      <td>20-06-28</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([government], [wants])</td>\n",
       "      <td>[government]</td>\n",
       "      <td>[wants]</td>\n",
       "      <td>government</td>\n",
       "      <td>wants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34441</th>\n",
       "      <td>85291798</td>\n",
       "      <td>20-06-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>([government], [offers])</td>\n",
       "      <td>[government]</td>\n",
       "      <td>[offers]</td>\n",
       "      <td>government</td>\n",
       "      <td>offers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34442</th>\n",
       "      <td>85294490</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([governments], [approved])</td>\n",
       "      <td>[governments]</td>\n",
       "      <td>[approved]</td>\n",
       "      <td>governments</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34443</th>\n",
       "      <td>85294490</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([government], [make])</td>\n",
       "      <td>[government]</td>\n",
       "      <td>[make]</td>\n",
       "      <td>government</td>\n",
       "      <td>make</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34444</th>\n",
       "      <td>85299191</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>GameSpot</td>\n",
       "      <td>([government], [announced])</td>\n",
       "      <td>[government]</td>\n",
       "      <td>[announced]</td>\n",
       "      <td>government</td>\n",
       "      <td>announced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34445 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Date            News_source_name  \\\n",
       "0      85330111  20-07-03             Washington Post   \n",
       "1      85395800  20-07-11                      YAHOO!   \n",
       "2      85543408  20-07-30                    NBC News   \n",
       "3      85068543  20-06-01  Milwaukee Journal Sentinel   \n",
       "4      85101644  20-06-05                      E News   \n",
       "...         ...       ...                         ...   \n",
       "34440  85288194  20-06-28                      Reason   \n",
       "34441  85291798  20-06-28                         NaN   \n",
       "34442  85294490  20-06-29                      Reason   \n",
       "34443  85294490  20-06-29                      Reason   \n",
       "34444  85299191  20-06-29                    GameSpot   \n",
       "\n",
       "                                   SVs                  S              V  \\\n",
       "0      ([Breonna, Taylor], [sleeping])  [Breonna, Taylor]     [sleeping]   \n",
       "1          ([Breonna, Taylor], [used])  [Breonna, Taylor]         [used]   \n",
       "2         ([Breonna, Taylor], [cover])  [Breonna, Taylor]        [cover]   \n",
       "3        ([Breonna, Taylor], [wanted])  [Breonna, Taylor]       [wanted]   \n",
       "4           ([Breonna], [celebrating])          [Breonna]  [celebrating]   \n",
       "...                                ...                ...            ...   \n",
       "34440          ([government], [wants])       [government]        [wants]   \n",
       "34441         ([government], [offers])       [government]       [offers]   \n",
       "34442      ([governments], [approved])      [governments]     [approved]   \n",
       "34443           ([government], [make])       [government]         [make]   \n",
       "34444      ([government], [announced])       [government]    [announced]   \n",
       "\n",
       "             S_string     V_string Side  \n",
       "0      Breonna Taylor     sleeping   -1  \n",
       "1      Breonna Taylor         used   -1  \n",
       "2      Breonna Taylor        cover   -1  \n",
       "3      Breonna Taylor       wanted   -1  \n",
       "4             Breonna  celebrating   -1  \n",
       "...               ...          ...  ...  \n",
       "34440      government        wants    1  \n",
       "34441      government       offers    1  \n",
       "34442     governments     approved    1  \n",
       "34443      government         make    1  \n",
       "34444      government    announced    1  \n",
       "\n",
       "[34445 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering to see how many BLM relevant Subjects there are in SV df\n",
    "# adding a numeric code, representing the following: -1 = BLM side (against authority - liberal), 1 = anti-BLM side (for authority - conservative), 0 = shoudl trigger disapproval by both sides, e.g. Zimmerman, brutality, Chauvin\n",
    "\n",
    "SV_df_nona_breonna_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Breonna\", case = False)]\n",
    "SV_df_nona_breonna_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_floyd_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Floyd\", case = False)]\n",
    "SV_df_nona_floyd_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_trayvon_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Trayvon\", case = False)]\n",
    "SV_df_nona_trayvon_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_movement_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"movement\", case = False)]\n",
    "SV_df_nona_movement_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_blacklivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Black Lives Matter\", case = False)]\n",
    "SV_df_nona_blacklivesmatter_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_blm_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"BLM\", case = False)]\n",
    "SV_df_nona_blm_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_htblacklivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"#BlackLivesMatter\", case = False)]\n",
    "SV_df_nona_htblacklivesmatter_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_protester_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"protester\", case = False)]\n",
    "SV_df_nona_protester_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_demonstrator_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"demonstrator\", case = False)]\n",
    "SV_df_nona_demonstrator_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_nationalguard_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"National Guard\", case = False)]\n",
    "SV_df_nona_nationalguard_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_bluelivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Blue Lives Matter\", case = False)]\n",
    "SV_df_nona_bluelivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_htbluelivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"#BlueLivesMatter\", case = False)]\n",
    "SV_df_nona_htbluelivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_alllivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"All Lives Matter\", case = False)]\n",
    "SV_df_nona_alllivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_htalllivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"#AllLivesMatter\", case = False)]\n",
    "SV_df_nona_htalllivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_police_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"police\", case = False)]\n",
    "SV_df_nona_police_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_government_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"government\", case = False)]\n",
    "SV_df_nona_government_S[\"Side\"] = \"1\"\n",
    "\n",
    "\n",
    "SV_df_nona_terms = pd.concat([SV_df_nona_breonna_S,\n",
    "                               SV_df_nona_floyd_S,\n",
    "                               SV_df_nona_trayvon_S,\n",
    "                               SV_df_nona_movement_S,\n",
    "                               SV_df_nona_blacklivesmatter_S,\n",
    "                               SV_df_nona_blm_S,\n",
    "                               SV_df_nona_htblacklivesmatter_S,\n",
    "                               SV_df_nona_protester_S,\n",
    "                               SV_df_nona_demonstrator_S,\n",
    "                               SV_df_nona_nationalguard_S,\n",
    "                               SV_df_nona_bluelivesmatter_S,\n",
    "                               SV_df_nona_htbluelivesmatter_S,\n",
    "                               SV_df_nona_alllivesmatter_S,\n",
    "                               SV_df_nona_htalllivesmatter_S,\n",
    "                               SV_df_nona_police_S,\n",
    "                               SV_df_nona_government_S\n",
    "                              ],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "SV_df_nona_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae659e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-fc976a512bcc>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_breonna_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_floyd_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_trayvon_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_movement_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_blacklivesmatter_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_blm_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_protester_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_demonstrator_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-5-fc976a512bcc>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_nationalguard_O[\"Side\"] = \"1\"\n",
      "<ipython-input-5-fc976a512bcc>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_bluelivesmatter_O[\"Side\"] = \"1\"\n",
      "<ipython-input-5-fc976a512bcc>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_alllivesmatter_O[\"Side\"] = \"1\"\n",
      "<ipython-input-5-fc976a512bcc>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_police_O[\"Side\"] = \"1\"\n",
      "<ipython-input-5-fc976a512bcc>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_government_O[\"Side\"] = \"1\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>VOs</th>\n",
       "      <th>V</th>\n",
       "      <th>O</th>\n",
       "      <th>V_string</th>\n",
       "      <th>O_string</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31964104</td>\n",
       "      <td>20-07-18</td>\n",
       "      <td>vulture.com</td>\n",
       "      <td>([mentions], [Breonna, Taylor])</td>\n",
       "      <td>[mentions]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>mentions</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31972010</td>\n",
       "      <td>20-07-23</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>([murdered], [Breonna, Taylor])</td>\n",
       "      <td>[murdered]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>murdered</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31874644</td>\n",
       "      <td>20-06-01</td>\n",
       "      <td>nymag.com</td>\n",
       "      <td>([killed], [Breonna, Taylor])</td>\n",
       "      <td>[killed]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>killed</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31882645</td>\n",
       "      <td>20-06-05</td>\n",
       "      <td>chicago.suntimes.com</td>\n",
       "      <td>([named], [[Breonna, Taylor], [Johnson]])</td>\n",
       "      <td>[named]</td>\n",
       "      <td>[[Breonna, Taylor], [Johnson]]</td>\n",
       "      <td>named</td>\n",
       "      <td>[Breonna Taylor] [Johnson]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31883040</td>\n",
       "      <td>20-06-05</td>\n",
       "      <td>euronews.com</td>\n",
       "      <td>([shot], [Breonna, Taylor])</td>\n",
       "      <td>[shot]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>shot</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>85238290</td>\n",
       "      <td>20-06-22</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([devised], [Government])</td>\n",
       "      <td>[devised]</td>\n",
       "      <td>[Government]</td>\n",
       "      <td>devised</td>\n",
       "      <td>Government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587</th>\n",
       "      <td>85255498</td>\n",
       "      <td>20-06-24</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([supposed], [government])</td>\n",
       "      <td>[supposed]</td>\n",
       "      <td>[government]</td>\n",
       "      <td>supposed</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9588</th>\n",
       "      <td>85255498</td>\n",
       "      <td>20-06-24</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([identify], [government])</td>\n",
       "      <td>[identify]</td>\n",
       "      <td>[government]</td>\n",
       "      <td>identify</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589</th>\n",
       "      <td>85269390</td>\n",
       "      <td>20-06-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>([accused], [government])</td>\n",
       "      <td>[accused]</td>\n",
       "      <td>[government]</td>\n",
       "      <td>accused</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>85278396</td>\n",
       "      <td>20-06-27</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>([given], [governments])</td>\n",
       "      <td>[given]</td>\n",
       "      <td>[governments]</td>\n",
       "      <td>given</td>\n",
       "      <td>governments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9591 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID      Date      News_source_name  \\\n",
       "0     31964104  20-07-18           vulture.com   \n",
       "1     31972010  20-07-23    washingtonpost.com   \n",
       "2     31874644  20-06-01             nymag.com   \n",
       "3     31882645  20-06-05  chicago.suntimes.com   \n",
       "4     31883040  20-06-05          euronews.com   \n",
       "...        ...       ...                   ...   \n",
       "9586  85238290  20-06-22                Reason   \n",
       "9587  85255498  20-06-24                Reason   \n",
       "9588  85255498  20-06-24                Reason   \n",
       "9589  85269390  20-06-25                   NaN   \n",
       "9590  85278396  20-06-27    Al Jazeera English   \n",
       "\n",
       "                                            VOs           V  \\\n",
       "0               ([mentions], [Breonna, Taylor])  [mentions]   \n",
       "1               ([murdered], [Breonna, Taylor])  [murdered]   \n",
       "2                 ([killed], [Breonna, Taylor])    [killed]   \n",
       "3     ([named], [[Breonna, Taylor], [Johnson]])     [named]   \n",
       "4                   ([shot], [Breonna, Taylor])      [shot]   \n",
       "...                                         ...         ...   \n",
       "9586                  ([devised], [Government])   [devised]   \n",
       "9587                 ([supposed], [government])  [supposed]   \n",
       "9588                 ([identify], [government])  [identify]   \n",
       "9589                  ([accused], [government])   [accused]   \n",
       "9590                   ([given], [governments])     [given]   \n",
       "\n",
       "                                   O  V_string                    O_string  \\\n",
       "0                  [Breonna, Taylor]  mentions              Breonna Taylor   \n",
       "1                  [Breonna, Taylor]  murdered              Breonna Taylor   \n",
       "2                  [Breonna, Taylor]    killed              Breonna Taylor   \n",
       "3     [[Breonna, Taylor], [Johnson]]     named  [Breonna Taylor] [Johnson]   \n",
       "4                  [Breonna, Taylor]      shot              Breonna Taylor   \n",
       "...                              ...       ...                         ...   \n",
       "9586                    [Government]   devised                  Government   \n",
       "9587                    [government]  supposed                  government   \n",
       "9588                    [government]  identify                  government   \n",
       "9589                    [government]   accused                  government   \n",
       "9590                   [governments]     given                 governments   \n",
       "\n",
       "     Side  \n",
       "0      -1  \n",
       "1      -1  \n",
       "2      -1  \n",
       "3      -1  \n",
       "4      -1  \n",
       "...   ...  \n",
       "9586    1  \n",
       "9587    1  \n",
       "9588    1  \n",
       "9589    1  \n",
       "9590    1  \n",
       "\n",
       "[9591 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering to see how many BLM relevant Objects there are in VO df\n",
    "# adding a numeric code, representing the following: -1 = BLM side (against authority - liberal), 1 = anti-BLM side (for authority - conservative), 0 = shoudl trigger disapproval by both sides, e.g. Zimmerman, brutality, Chauvin\n",
    "\n",
    "VO_df_nona_breonna_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Breonna\", case = False)]\n",
    "VO_df_nona_breonna_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_floyd_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Floyd\", case = False)]\n",
    "VO_df_nona_floyd_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_trayvon_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Trayvon\", case = False)]\n",
    "VO_df_nona_trayvon_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_movement_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"movement\", case = False)]\n",
    "VO_df_nona_movement_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_blacklivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Black Lives Matter\", case = False)]\n",
    "VO_df_nona_blacklivesmatter_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_blm_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"BLM\", case = False)]\n",
    "VO_df_nona_blm_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_htblacklivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"#BlackLivesMatter\", case = False)]\n",
    "VO_df_nona_htblacklivesmatter_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_protester_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"protester\", case = False)]\n",
    "VO_df_nona_protester_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_demonstrator_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"demonstrator\", case = False)]\n",
    "VO_df_nona_demonstrator_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_nationalguard_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"National Guard\", case = False)]\n",
    "VO_df_nona_nationalguard_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_bluelivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Blue Lives Matter\", case = False)]\n",
    "VO_df_nona_bluelivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_htbluelivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"#BlueLivesMatter\", case = False)]\n",
    "VO_df_nona_htbluelivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_alllivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"All Lives Matter\", case = False)]\n",
    "VO_df_nona_alllivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_htalllivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"#AllLivesMatter\", case = False)]\n",
    "VO_df_nona_htalllivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_police_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"police\", case = False)]\n",
    "VO_df_nona_police_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_government_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"government\", case = False)]\n",
    "VO_df_nona_government_O[\"Side\"] = \"1\"\n",
    "\n",
    "VO_df_nona_terms = pd.concat([VO_df_nona_breonna_O,\n",
    "                               VO_df_nona_floyd_O,\n",
    "                               VO_df_nona_trayvon_O,\n",
    "                               VO_df_nona_movement_O,\n",
    "                               VO_df_nona_blacklivesmatter_O,\n",
    "                               VO_df_nona_blm_O,\n",
    "                               VO_df_nona_htblacklivesmatter_O,\n",
    "                               VO_df_nona_protester_O,\n",
    "                               VO_df_nona_demonstrator_O,\n",
    "                               VO_df_nona_nationalguard_O,\n",
    "                               VO_df_nona_bluelivesmatter_O,\n",
    "                               VO_df_nona_htbluelivesmatter_O,\n",
    "                               VO_df_nona_alllivesmatter_O,\n",
    "                               VO_df_nona_htalllivesmatter_O,\n",
    "                               VO_df_nona_police_O,\n",
    "                               VO_df_nona_government_O\n",
    "                              ],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "VO_df_nona_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6f6ff",
   "metadata": {},
   "source": [
    "## Lemmatizing the V columns to enable the merger with connotation score dataset, and to allow for later analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba600e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on filtered term list dfs from above\n",
    "# following this guide: https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "# import these modules\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_fun(verb):\n",
    "    verb_lemmatized = lemmatizer.lemmatize(verb, 'v')\n",
    "    return verb_lemmatized\n",
    "\n",
    "SV_df_nona_terms['V_lemmatized'] = SV_df_nona_terms.apply(lambda row: lemmatizer_fun(row[\"V_string\"]), axis = 1)\n",
    "VO_df_nona_terms['V_lemmatized'] = VO_df_nona_terms.apply(lambda row: lemmatizer_fun(row[\"V_string\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b86078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a287cf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85ba496",
   "metadata": {},
   "source": [
    "## Connotation dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd37aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>Perspective(wo)</th>\n",
       "      <th>Perspective(ws)</th>\n",
       "      <th>Perspective(so)</th>\n",
       "      <th>Effect(o)</th>\n",
       "      <th>Effect(s)</th>\n",
       "      <th>Value(o)</th>\n",
       "      <th>Value(s)</th>\n",
       "      <th>State(o)</th>\n",
       "      <th>State(s)</th>\n",
       "      <th>Perspective(ro)</th>\n",
       "      <th>Perspective(rs)</th>\n",
       "      <th>Perspective(os)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>breed</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>enrich</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>court</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>reconcile</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>displace</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          verb  Perspective(wo)  Perspective(ws)  Perspective(so)  Effect(o)  \\\n",
       "0         have         0.366667         0.333333         0.466667   0.066667   \n",
       "1          say         0.000000         0.166667         0.066667   0.133333   \n",
       "2         make        -0.066667         0.100000         0.100000   0.466667   \n",
       "3         take         0.500000         0.600000         0.800000   0.133333   \n",
       "4           go         0.066667         0.133333         0.200000   0.000000   \n",
       "..         ...              ...              ...              ...        ...   \n",
       "942      breed        -0.366667        -0.500000         0.000000   0.266667   \n",
       "943     enrich         0.566667         0.533333         0.300000   0.866667   \n",
       "944      court         0.266667         0.433333         0.366667   0.400000   \n",
       "945  reconcile         0.400000         0.566667         0.133333   0.533333   \n",
       "946   displace         0.133333        -0.233333        -0.133333  -0.666667   \n",
       "\n",
       "     Effect(s)  Value(o)  Value(s)  State(o)  State(s)  Perspective(ro)  \\\n",
       "0     0.200000  0.466667  0.600000  0.066667  0.366667         0.400000   \n",
       "1     0.066667  0.066667  1.000000  0.000000  0.100000         0.033333   \n",
       "2    -0.066667  0.200000  1.000000  0.000000  0.166667        -0.033333   \n",
       "3     0.600000  0.466667  0.600000  0.033333  0.666667         0.500000   \n",
       "4     0.066667 -0.066667  0.466667 -0.100000  0.033333         0.066667   \n",
       "..         ...       ...       ...       ...       ...              ...   \n",
       "942  -0.066667  0.066667  0.066667 -0.166667 -0.100000        -0.400000   \n",
       "943   0.266667  1.000000  0.600000  0.433333  0.400000         0.466667   \n",
       "944   0.400000  0.866667  1.000000  0.333333  0.466667         0.333333   \n",
       "945   0.333333  0.600000  0.466667  0.400000  0.033333         0.566667   \n",
       "946   0.200000  0.733333  0.066667 -0.733333 -0.033333         0.100000   \n",
       "\n",
       "     Perspective(rs)  Perspective(os)  \n",
       "0           0.366667         0.066667  \n",
       "1           0.266667         0.000000  \n",
       "2           0.200000         0.000000  \n",
       "3           0.566667         0.066667  \n",
       "4           0.066667        -0.100000  \n",
       "..               ...              ...  \n",
       "942        -0.500000         0.000000  \n",
       "943         0.433333         0.533333  \n",
       "944         0.366667         0.300000  \n",
       "945         0.600000         0.433333  \n",
       "946        -0.133333        -0.733333  \n",
       "\n",
       "[947 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connotation scores originating from this paper: https://aclanthology.org/P16-1030.pdf\n",
    "\n",
    "connotation_df = pd.read_csv(\"data/connotation_dataset/full_frame_info.txt\", sep='\\t')\n",
    "connotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d881ec07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>Perspective(wo)</th>\n",
       "      <th>Perspective(ws)</th>\n",
       "      <th>Perspective(so)</th>\n",
       "      <th>Effect(o)</th>\n",
       "      <th>Effect(s)</th>\n",
       "      <th>Value(o)</th>\n",
       "      <th>Value(s)</th>\n",
       "      <th>State(o)</th>\n",
       "      <th>State(s)</th>\n",
       "      <th>Perspective(ro)</th>\n",
       "      <th>Perspective(rs)</th>\n",
       "      <th>Perspective(os)</th>\n",
       "      <th>V_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>breed</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>breed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>enrich</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>enrich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>court</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>reconcile</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>displace</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>displace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          verb  Perspective(wo)  Perspective(ws)  Perspective(so)  Effect(o)  \\\n",
       "0         have         0.366667         0.333333         0.466667   0.066667   \n",
       "1          say         0.000000         0.166667         0.066667   0.133333   \n",
       "2         make        -0.066667         0.100000         0.100000   0.466667   \n",
       "3         take         0.500000         0.600000         0.800000   0.133333   \n",
       "4           go         0.066667         0.133333         0.200000   0.000000   \n",
       "..         ...              ...              ...              ...        ...   \n",
       "942      breed        -0.366667        -0.500000         0.000000   0.266667   \n",
       "943     enrich         0.566667         0.533333         0.300000   0.866667   \n",
       "944      court         0.266667         0.433333         0.366667   0.400000   \n",
       "945  reconcile         0.400000         0.566667         0.133333   0.533333   \n",
       "946   displace         0.133333        -0.233333        -0.133333  -0.666667   \n",
       "\n",
       "     Effect(s)  Value(o)  Value(s)  State(o)  State(s)  Perspective(ro)  \\\n",
       "0     0.200000  0.466667  0.600000  0.066667  0.366667         0.400000   \n",
       "1     0.066667  0.066667  1.000000  0.000000  0.100000         0.033333   \n",
       "2    -0.066667  0.200000  1.000000  0.000000  0.166667        -0.033333   \n",
       "3     0.600000  0.466667  0.600000  0.033333  0.666667         0.500000   \n",
       "4     0.066667 -0.066667  0.466667 -0.100000  0.033333         0.066667   \n",
       "..         ...       ...       ...       ...       ...              ...   \n",
       "942  -0.066667  0.066667  0.066667 -0.166667 -0.100000        -0.400000   \n",
       "943   0.266667  1.000000  0.600000  0.433333  0.400000         0.466667   \n",
       "944   0.400000  0.866667  1.000000  0.333333  0.466667         0.333333   \n",
       "945   0.333333  0.600000  0.466667  0.400000  0.033333         0.566667   \n",
       "946   0.200000  0.733333  0.066667 -0.733333 -0.033333         0.100000   \n",
       "\n",
       "     Perspective(rs)  Perspective(os) V_lemmatized  \n",
       "0           0.366667         0.066667         have  \n",
       "1           0.266667         0.000000          say  \n",
       "2           0.200000         0.000000         make  \n",
       "3           0.566667         0.066667         take  \n",
       "4           0.066667        -0.100000           go  \n",
       "..               ...              ...          ...  \n",
       "942        -0.500000         0.000000        breed  \n",
       "943         0.433333         0.533333       enrich  \n",
       "944         0.366667         0.300000        court  \n",
       "945         0.600000         0.433333    reconcile  \n",
       "946        -0.133333        -0.733333     displace  \n",
       "\n",
       "[947 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatizing connotation score df to make sure it can be matched to the SV, VO dataframes by verb\n",
    "\n",
    "# following this guide: https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "# import these modules\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_fun(verb):\n",
    "    verb_lemmatized = lemmatizer.lemmatize(verb, 'v')\n",
    "    return verb_lemmatized\n",
    "\n",
    "connotation_df['V_lemmatized'] = connotation_df.apply(lambda row: lemmatizer_fun(row[\"verb\"]), axis = 1)\n",
    "\n",
    "connotation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0087ae32",
   "metadata": {},
   "source": [
    "## Merging filtered SV, VO dfs with connotation frame scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e33213d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# running on filtered term list dfs from above\n",
    "\n",
    "SV_df_nona_terms_connotation = SV_df_nona_terms.merge(connotation_df, on = 'V_lemmatized', how = 'left')\n",
    "\n",
    "VO_df_nona_terms_connotation = VO_df_nona_terms.merge(connotation_df, on = 'V_lemmatized', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2064259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4396\n",
      "1790\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# running on filtered term list dfs from above\n",
    "\n",
    "# removing rows that have no connotation rating for the verb\n",
    "\n",
    "print(SV_df_nona_terms_connotation.verb.isna().sum())\n",
    "print(VO_df_nona_terms_connotation.verb.isna().sum())\n",
    "\n",
    "term_list_df_SV_connotation_nonaverb = SV_df_nona_terms_connotation[SV_df_nona_terms_connotation['verb'].notna()]\n",
    "term_list_df_VO_connotation_nonaverb = VO_df_nona_terms_connotation[VO_df_nona_terms_connotation['verb'].notna()]\n",
    "\n",
    "print(term_list_df_SV_connotation_nonaverb.verb.isna().sum())\n",
    "print(term_list_df_VO_connotation_nonaverb.verb.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda91e1",
   "metadata": {},
   "source": [
    "## News media bias sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8be8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_in_NOW_data</th>\n",
       "      <th>name_in_allsides_data</th>\n",
       "      <th>media_bias_rating</th>\n",
       "      <th>accessed</th>\n",
       "      <th>column</th>\n",
       "      <th>url</th>\n",
       "      <th>url_allsides</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Axios</td>\n",
       "      <td>Axios</td>\n",
       "      <td>Center</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.axios.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/axios</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barron's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Center</td>\n",
       "      <td>Ad Fontes Media Bias Chart 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Center</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>allsides</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Insider on MSN.com</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Center</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>allsides</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>businessinsider.com</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Center</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>allsides</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>The Raw Story</td>\n",
       "      <td>Raw Story</td>\n",
       "      <td>Left</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.rawstory.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/raw-story</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Fox News</td>\n",
       "      <td>Fox News (Online News)</td>\n",
       "      <td>Right</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.foxnews.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/fox-news-...</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>foxnews.com</td>\n",
       "      <td>Fox News (Online News)</td>\n",
       "      <td>Right</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.foxnews.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/fox-news-...</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ksl.com</td>\n",
       "      <td>KSL</td>\n",
       "      <td>Right</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.ksl.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/ksl</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>LifeSiteNews</td>\n",
       "      <td>Life Site News</td>\n",
       "      <td>Right</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>media_bias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name_in_NOW_data   name_in_allsides_data media_bias_rating  \\\n",
       "0                          Axios                   Axios            Center   \n",
       "1                       Barron's                     NaN            Center   \n",
       "2               Business Insider        Business Insider            Center   \n",
       "3    Business Insider on MSN.com        Business Insider            Center   \n",
       "4            businessinsider.com        Business Insider            Center   \n",
       "..                           ...                     ...               ...   \n",
       "160                The Raw Story               Raw Story              Left   \n",
       "161                     Fox News  Fox News (Online News)             Right   \n",
       "162                  foxnews.com  Fox News (Online News)             Right   \n",
       "163                      ksl.com                     KSL             Right   \n",
       "164                 LifeSiteNews          Life Site News             Right   \n",
       "\n",
       "                            accessed      column                       url  \\\n",
       "0        from AllSides December 2021         NaN    https://www.axios.com/   \n",
       "1    Ad Fontes Media Bias Chart 2021         NaN                       NaN   \n",
       "2               from supervisor 2019    allsides                       NaN   \n",
       "3               from supervisor 2019    allsides                       NaN   \n",
       "4               from supervisor 2019    allsides                       NaN   \n",
       "..                               ...         ...                       ...   \n",
       "160      from AllSides December 2021         NaN  http://www.rawstory.com/   \n",
       "161      from AllSides December 2021         NaN   http://www.foxnews.com/   \n",
       "162      from AllSides December 2021         NaN   http://www.foxnews.com/   \n",
       "163      from AllSides December 2021         NaN       http://www.ksl.com/   \n",
       "164             from supervisor 2019  media_bias                       NaN   \n",
       "\n",
       "                                          url_allsides    category  \n",
       "0           https://www.allsides.com/news-source/axios  News Media  \n",
       "1                                                  NaN         NaN  \n",
       "2                                                  NaN         NaN  \n",
       "3                                                  NaN         NaN  \n",
       "4                                                  NaN         NaN  \n",
       "..                                                 ...         ...  \n",
       "160     https://www.allsides.com/news-source/raw-story  News Media  \n",
       "161  https://www.allsides.com/news-source/fox-news-...  News Media  \n",
       "162  https://www.allsides.com/news-source/fox-news-...  News Media  \n",
       "163           https://www.allsides.com/news-source/ksl  News Media  \n",
       "164                                                NaN         NaN  \n",
       "\n",
       "[165 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in media bias df\n",
    "\n",
    "media_bias_df = pd.read_csv(\"data/news_political_alignment_ratings/news_sources_matching_bestversion.csv\", sep = ';')\n",
    "\n",
    "media_bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae249c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30159\n",
      "7811\n"
     ]
    }
   ],
   "source": [
    "# renaming SV, VO dfs news source column to enable left join merger\n",
    "\n",
    "term_list_df_SV_connotation_nonaverb = term_list_df_SV_connotation_nonaverb.rename(columns={'News_source_name': 'name_in_NOW_data'})\n",
    "term_list_df_VO_connotation_nonaverb = term_list_df_VO_connotation_nonaverb.rename(columns={'News_source_name': 'name_in_NOW_data'})\n",
    "\n",
    "print(len(term_list_df_SV_connotation_nonaverb))\n",
    "print(len(term_list_df_VO_connotation_nonaverb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33787086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# left joining media bias df to the SV, VO dataframes\n",
    "\n",
    "SV_connotation_bias_df = term_list_df_SV_connotation_nonaverb.merge(media_bias_df, on = 'name_in_NOW_data', how = 'left')\n",
    "VO_connotation_bias_df = term_list_df_VO_connotation_nonaverb.merge(media_bias_df, on = 'name_in_NOW_data', how = 'left')\n",
    "\n",
    "SV_connotation_bias_df.to_csv(\"data/NOW_preprocessed/SV_BLM_bias_connotation_combined.csv\", index = False)\n",
    "VO_connotation_bias_df.to_csv(\"data/NOW_preprocessed/VO_BLM_bias_connotation_combined.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b7591",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
