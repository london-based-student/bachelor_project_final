{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00eb2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085437\n",
      "570373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SV_df = pd.read_csv(\"data/NOW_preprocessed/total_SV_df.csv\")\n",
    "VO_df = pd.read_csv(\"data/NOW_preprocessed/total_VO_df.csv\")\n",
    "\n",
    "print(len(SV_df))\n",
    "print(len(VO_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debcfc53",
   "metadata": {},
   "source": [
    "## Bringing SV, VO columns to a preprocessed format ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f765bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "202\n",
      "0\n",
      "0\n",
      "1085430\n",
      "570171\n"
     ]
    }
   ],
   "source": [
    "# checking how many NAs there are\n",
    "\n",
    "print(SV_df['SVs'].isna().sum()) \n",
    "print(VO_df['VOs'].isna().sum())\n",
    "\n",
    "# removing the NAs\n",
    "\n",
    "SV_df_nona = SV_df[SV_df['SVs'].notna()]\n",
    "VO_df_nona = VO_df[VO_df['VOs'].notna()]\n",
    "\n",
    "\n",
    "print(SV_df_nona['SVs'].isna().sum()) \n",
    "print(VO_df_nona['VOs'].isna().sum())\n",
    "\n",
    "print(len(SV_df_nona))\n",
    "print(len(VO_df_nona))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97c9171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-252833377575>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona['S_string'] = SV_df_nona['S'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-14-252833377575>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona['S_string'] = SV_df_nona.apply(lambda row: text_cleaner(row[\"S_string\"]), axis = 1)\n",
      "<ipython-input-14-252833377575>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona['V_string'] = SV_df_nona['V'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-14-252833377575>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona['V_string'] = VO_df_nona['V'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-14-252833377575>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona['O_string'] = VO_df_nona['O'].apply(lambda x: x[1:-1])\n",
      "<ipython-input-14-252833377575>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona['O_string'] = VO_df_nona.apply(lambda row: text_cleaner(row[\"O_string\"]), axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>VOs</th>\n",
       "      <th>V</th>\n",
       "      <th>O</th>\n",
       "      <th>V_string</th>\n",
       "      <th>O_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([seen], [[John, Hickenlooper], [Colorado, Sen...</td>\n",
       "      <td>[seen]</td>\n",
       "      <td>[[John, Hickenlooper], [Colorado, Senate, Prim...</td>\n",
       "      <td>seen</td>\n",
       "      <td>[John Hickenlooper] [Colorado Senate Primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([made], [missteps])</td>\n",
       "      <td>[made]</td>\n",
       "      <td>[missteps]</td>\n",
       "      <td>made</td>\n",
       "      <td>missteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([hide], [caption])</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[caption]</td>\n",
       "      <td>hide</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([considered], [John, Hickenlooper])</td>\n",
       "      <td>[considered]</td>\n",
       "      <td>[John, Hickenlooper]</td>\n",
       "      <td>considered</td>\n",
       "      <td>John Hickenlooper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31930103</td>\n",
       "      <td>20-07-01</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>([made], [missteps])</td>\n",
       "      <td>[made]</td>\n",
       "      <td>[missteps]</td>\n",
       "      <td>made</td>\n",
       "      <td>missteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570368</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([posted], [gains])</td>\n",
       "      <td>[posted]</td>\n",
       "      <td>[gains]</td>\n",
       "      <td>posted</td>\n",
       "      <td>gains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570369</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([led], [way])</td>\n",
       "      <td>[led]</td>\n",
       "      <td>[way]</td>\n",
       "      <td>led</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570370</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([averaged], [viewers])</td>\n",
       "      <td>[averaged]</td>\n",
       "      <td>[viewers]</td>\n",
       "      <td>averaged</td>\n",
       "      <td>viewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570371</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([drew], [viewers])</td>\n",
       "      <td>[drew]</td>\n",
       "      <td>[viewers]</td>\n",
       "      <td>drew</td>\n",
       "      <td>viewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570372</th>\n",
       "      <td>85309194</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([won], [crown])</td>\n",
       "      <td>[won]</td>\n",
       "      <td>[crown]</td>\n",
       "      <td>won</td>\n",
       "      <td>crown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570171 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID      Date News_source_name  \\\n",
       "0       31930103  20-07-01          npr.org   \n",
       "1       31930103  20-07-01          npr.org   \n",
       "2       31930103  20-07-01          npr.org   \n",
       "3       31930103  20-07-01          npr.org   \n",
       "4       31930103  20-07-01          npr.org   \n",
       "...          ...       ...              ...   \n",
       "570368  85309194  20-06-30           YAHOO!   \n",
       "570369  85309194  20-06-30           YAHOO!   \n",
       "570370  85309194  20-06-30           YAHOO!   \n",
       "570371  85309194  20-06-30           YAHOO!   \n",
       "570372  85309194  20-06-30           YAHOO!   \n",
       "\n",
       "                                                      VOs             V  \\\n",
       "0       ([seen], [[John, Hickenlooper], [Colorado, Sen...        [seen]   \n",
       "1                                    ([made], [missteps])        [made]   \n",
       "2                                     ([hide], [caption])        [hide]   \n",
       "3                    ([considered], [John, Hickenlooper])  [considered]   \n",
       "4                                    ([made], [missteps])        [made]   \n",
       "...                                                   ...           ...   \n",
       "570368                                ([posted], [gains])      [posted]   \n",
       "570369                                     ([led], [way])         [led]   \n",
       "570370                            ([averaged], [viewers])    [averaged]   \n",
       "570371                                ([drew], [viewers])        [drew]   \n",
       "570372                                   ([won], [crown])         [won]   \n",
       "\n",
       "                                                        O    V_string  \\\n",
       "0       [[John, Hickenlooper], [Colorado, Senate, Prim...        seen   \n",
       "1                                              [missteps]        made   \n",
       "2                                               [caption]        hide   \n",
       "3                                    [John, Hickenlooper]  considered   \n",
       "4                                              [missteps]        made   \n",
       "...                                                   ...         ...   \n",
       "570368                                            [gains]      posted   \n",
       "570369                                              [way]         led   \n",
       "570370                                          [viewers]    averaged   \n",
       "570371                                          [viewers]        drew   \n",
       "570372                                            [crown]         won   \n",
       "\n",
       "                                             O_string  \n",
       "0       [John Hickenlooper] [Colorado Senate Primary]  \n",
       "1                                            missteps  \n",
       "2                                             caption  \n",
       "3                                   John Hickenlooper  \n",
       "4                                            missteps  \n",
       "...                                               ...  \n",
       "570368                                          gains  \n",
       "570369                                            way  \n",
       "570370                                        viewers  \n",
       "570371                                        viewers  \n",
       "570372                                          crown  \n",
       "\n",
       "[570171 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking the S, V, O columns out of list format, making it into string:\n",
    "\n",
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text_cleaned = re.sub(r\",\", \"\", text) \n",
    "    return text_cleaned\n",
    "\n",
    "\n",
    "# making the list column into string on the SV df\n",
    "\n",
    "SV_df_nona['S_string'] = SV_df_nona['S'].apply(lambda x: x[1:-1])\n",
    "SV_df_nona['S_string'] = SV_df_nona.apply(lambda row: text_cleaner(row[\"S_string\"]), axis = 1)\n",
    "SV_df_nona['V_string'] = SV_df_nona['V'].apply(lambda x: x[1:-1])\n",
    "\n",
    "SV_df_nona\n",
    "\n",
    "\n",
    "# making the list column into string on the VO df\n",
    "\n",
    "VO_df_nona['V_string'] = VO_df_nona['V'].apply(lambda x: x[1:-1])\n",
    "VO_df_nona['O_string'] = VO_df_nona['O'].apply(lambda x: x[1:-1])\n",
    "VO_df_nona['O_string'] = VO_df_nona.apply(lambda row: text_cleaner(row[\"O_string\"]), axis = 1)\n",
    "\n",
    "VO_df_nona\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f301bc4",
   "metadata": {},
   "source": [
    "### filtering for S and O that includes BLM relevant terms. Worthy revisions: extend term list, save to csv. #### Important to note: if term list fitlers are changed, the news sources have to be reassessed. Additional news sources might be inlcuded in the exported csv files, which have to be checked for bias ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d483692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-dab6c7c306db>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_breonna_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_floyd_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_zimmerman_S[\"Side\"] = \"0\"\n",
      "<ipython-input-15-dab6c7c306db>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_trayvon_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_movement_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_blacklivesmatter_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_blm_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_protester_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_demonstrator_S[\"Side\"] = \"-1\"\n",
      "<ipython-input-15-dab6c7c306db>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_nationalguard_S[\"Side\"] = \"1\"\n",
      "<ipython-input-15-dab6c7c306db>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_chauvin_S[\"Side\"] = \"0\"\n",
      "<ipython-input-15-dab6c7c306db>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_bluelivesmatter_S[\"Side\"] = \"1\"\n",
      "<ipython-input-15-dab6c7c306db>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_police_S[\"Side\"] = \"1\"\n",
      "<ipython-input-15-dab6c7c306db>:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_brutality_S[\"Side\"] = \"0\"\n",
      "<ipython-input-15-dab6c7c306db>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_government_S[\"Side\"] = \"1\"\n",
      "<ipython-input-15-dab6c7c306db>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SV_df_nona_trump_S[\"Side\"] = \"1\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>SVs</th>\n",
       "      <th>S</th>\n",
       "      <th>V</th>\n",
       "      <th>S_string</th>\n",
       "      <th>V_string</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85330111</td>\n",
       "      <td>20-07-03</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>([Breonna, Taylor], [sleeping])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[sleeping]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85395800</td>\n",
       "      <td>20-07-11</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>([Breonna, Taylor], [used])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[used]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>used</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85543408</td>\n",
       "      <td>20-07-30</td>\n",
       "      <td>NBC News</td>\n",
       "      <td>([Breonna, Taylor], [cover])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[cover]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>cover</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85068543</td>\n",
       "      <td>20-06-01</td>\n",
       "      <td>Milwaukee Journal Sentinel</td>\n",
       "      <td>([Breonna, Taylor], [wanted])</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>[wanted]</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>wanted</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85101644</td>\n",
       "      <td>20-06-05</td>\n",
       "      <td>E News</td>\n",
       "      <td>([Breonna], [celebrating])</td>\n",
       "      <td>[Breonna]</td>\n",
       "      <td>[celebrating]</td>\n",
       "      <td>Breonna</td>\n",
       "      <td>celebrating</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50313</th>\n",
       "      <td>85294490</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([Donald, Trump], [encouraged])</td>\n",
       "      <td>[Donald, Trump]</td>\n",
       "      <td>[encouraged]</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>encouraged</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50314</th>\n",
       "      <td>85294490</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([Trump], [tried])</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>[tried]</td>\n",
       "      <td>Trump</td>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50315</th>\n",
       "      <td>85295191</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>([Trump], [won])</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>[won]</td>\n",
       "      <td>Trump</td>\n",
       "      <td>won</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50316</th>\n",
       "      <td>85296995</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>Adweek</td>\n",
       "      <td>([Trump], [posted])</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>[posted]</td>\n",
       "      <td>Trump</td>\n",
       "      <td>posted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50317</th>\n",
       "      <td>85301995</td>\n",
       "      <td>20-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>([Trump], [signed])</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>[signed]</td>\n",
       "      <td>Trump</td>\n",
       "      <td>signed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50318 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Date            News_source_name  \\\n",
       "0      85330111  20-07-03             Washington Post   \n",
       "1      85395800  20-07-11                      YAHOO!   \n",
       "2      85543408  20-07-30                    NBC News   \n",
       "3      85068543  20-06-01  Milwaukee Journal Sentinel   \n",
       "4      85101644  20-06-05                      E News   \n",
       "...         ...       ...                         ...   \n",
       "50313  85294490  20-06-29                      Reason   \n",
       "50314  85294490  20-06-29                      Reason   \n",
       "50315  85295191  20-06-29                    The Hill   \n",
       "50316  85296995  20-06-29                      Adweek   \n",
       "50317  85301995  20-06-30                         NaN   \n",
       "\n",
       "                                   SVs                  S              V  \\\n",
       "0      ([Breonna, Taylor], [sleeping])  [Breonna, Taylor]     [sleeping]   \n",
       "1          ([Breonna, Taylor], [used])  [Breonna, Taylor]         [used]   \n",
       "2         ([Breonna, Taylor], [cover])  [Breonna, Taylor]        [cover]   \n",
       "3        ([Breonna, Taylor], [wanted])  [Breonna, Taylor]       [wanted]   \n",
       "4           ([Breonna], [celebrating])          [Breonna]  [celebrating]   \n",
       "...                                ...                ...            ...   \n",
       "50313  ([Donald, Trump], [encouraged])    [Donald, Trump]   [encouraged]   \n",
       "50314               ([Trump], [tried])            [Trump]        [tried]   \n",
       "50315                 ([Trump], [won])            [Trump]          [won]   \n",
       "50316              ([Trump], [posted])            [Trump]       [posted]   \n",
       "50317              ([Trump], [signed])            [Trump]       [signed]   \n",
       "\n",
       "             S_string     V_string Side  \n",
       "0      Breonna Taylor     sleeping   -1  \n",
       "1      Breonna Taylor         used   -1  \n",
       "2      Breonna Taylor        cover   -1  \n",
       "3      Breonna Taylor       wanted   -1  \n",
       "4             Breonna  celebrating   -1  \n",
       "...               ...          ...  ...  \n",
       "50313    Donald Trump   encouraged    1  \n",
       "50314           Trump        tried    1  \n",
       "50315           Trump          won    1  \n",
       "50316           Trump       posted    1  \n",
       "50317           Trump       signed    1  \n",
       "\n",
       "[50318 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering to see how many BLM relevant Subjects there are in SV df\n",
    "# adding a numeric code, representing the following: -1 = BLM side (against authority - liberal), 1 = anti-BLM side (for authority - conservative), 0 = shoudl trigger disapproval by both sides, e.g. Zimmerman, brutality, Chauvin\n",
    "\n",
    "SV_df_nona_breonna_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Breonna\", case = False)]\n",
    "SV_df_nona_breonna_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_floyd_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Floyd\", case = False)]\n",
    "SV_df_nona_floyd_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_trayvon_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Trayvon\", case = False)]\n",
    "SV_df_nona_trayvon_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_movement_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"movement\", case = False)]\n",
    "SV_df_nona_movement_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_blacklivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Black Lives Matter\", case = False)]\n",
    "SV_df_nona_blacklivesmatter_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_blm_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"BLM\", case = False)]\n",
    "SV_df_nona_blm_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_htblacklivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"#BlackLivesMatter\", case = False)]\n",
    "SV_df_nona_htblacklivesmatter_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_protester_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"protester\", case = False)]\n",
    "SV_df_nona_protester_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_demonstrator_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"demonstrator\", case = False)]\n",
    "SV_df_nona_demonstrator_S[\"Side\"] = \"-1\"\n",
    "SV_df_nona_nationalguard_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"National Guard\", case = False)]\n",
    "SV_df_nona_nationalguard_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_bluelivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"Blue Lives Matter\", case = False)]\n",
    "SV_df_nona_bluelivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_htbluelivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"#BlueLivesMatter\", case = False)]\n",
    "SV_df_nona_htbluelivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_alllivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"All Lives Matter\", case = False)]\n",
    "SV_df_nona_alllivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_htalllivesmatter_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"#AllLivesMatter\", case = False)]\n",
    "SV_df_nona_htalllivesmatter_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_police_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"police\", case = False)]\n",
    "SV_df_nona_police_S[\"Side\"] = \"1\"\n",
    "SV_df_nona_government_S = SV_df_nona[SV_df_nona['S_string'].str.contains(\"government\", case = False)]\n",
    "SV_df_nona_government_S[\"Side\"] = \"1\"\n",
    "\n",
    "\n",
    "SV_df_nona_terms = pd.concat([SV_df_nona_breonna_S,\n",
    "                               SV_df_nona_floyd_S,\n",
    "                               SV_df_nona_trayvon_S,\n",
    "                               SV_df_nona_movement_S,\n",
    "                               SV_df_nona_blacklivesmatter_S,\n",
    "                               SV_df_nona_blm_S,\n",
    "                               SV_df_nona_htblacklivesmatter_S,\n",
    "                               SV_df_nona_protester_S,\n",
    "                               SV_df_nona_demonstrator_S,\n",
    "                               SV_df_nona_nationalguard_S,\n",
    "                               SV_df_nona_bluelivesmatter_S,\n",
    "                               SV_df_nona_htbluelivesmatter_S,\n",
    "                               SV_df_nona_alllivesmatter_S,\n",
    "                               SV_df_nona_htalllivesmatter_S,\n",
    "                               SV_df_nona_police_S,\n",
    "                               SV_df_nona_government_S\n",
    "                              ],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "SV_df_nona_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae659e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-9046417c32b7>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_breonna_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_floyd_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_zimmerman_O[\"Side\"] = \"0\"\n",
      "<ipython-input-16-9046417c32b7>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_trayvon_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_movement_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_blacklivesmatter_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_blm_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_protester_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_demonstrator_O[\"Side\"] = \"-1\"\n",
      "<ipython-input-16-9046417c32b7>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_nationalguard_O[\"Side\"] = \"1\"\n",
      "<ipython-input-16-9046417c32b7>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_chauvin_O[\"Side\"] = \"0\"\n",
      "<ipython-input-16-9046417c32b7>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_bluelivesmatter_O[\"Side\"] = \"1\"\n",
      "<ipython-input-16-9046417c32b7>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_alllivesmatter_O[\"Side\"] = \"1\"\n",
      "<ipython-input-16-9046417c32b7>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_police_O[\"Side\"] = \"1\"\n",
      "<ipython-input-16-9046417c32b7>:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_brutality_O[\"Side\"] = \"0\"\n",
      "<ipython-input-16-9046417c32b7>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_government_O[\"Side\"] = \"1\"\n",
      "<ipython-input-16-9046417c32b7>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  VO_df_nona_trump_O[\"Side\"] = \"1\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>News_source_name</th>\n",
       "      <th>VOs</th>\n",
       "      <th>V</th>\n",
       "      <th>O</th>\n",
       "      <th>V_string</th>\n",
       "      <th>O_string</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31964104</td>\n",
       "      <td>20-07-18</td>\n",
       "      <td>vulture.com</td>\n",
       "      <td>([mentions], [Breonna, Taylor])</td>\n",
       "      <td>[mentions]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>mentions</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31972010</td>\n",
       "      <td>20-07-23</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>([murdered], [Breonna, Taylor])</td>\n",
       "      <td>[murdered]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>murdered</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31874644</td>\n",
       "      <td>20-06-01</td>\n",
       "      <td>nymag.com</td>\n",
       "      <td>([killed], [Breonna, Taylor])</td>\n",
       "      <td>[killed]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>killed</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31882645</td>\n",
       "      <td>20-06-05</td>\n",
       "      <td>chicago.suntimes.com</td>\n",
       "      <td>([named], [[Breonna, Taylor], [Johnson]])</td>\n",
       "      <td>[named]</td>\n",
       "      <td>[[Breonna, Taylor], [Johnson]]</td>\n",
       "      <td>named</td>\n",
       "      <td>[Breonna Taylor] [Johnson]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31883040</td>\n",
       "      <td>20-06-05</td>\n",
       "      <td>euronews.com</td>\n",
       "      <td>([shot], [Breonna, Taylor])</td>\n",
       "      <td>[shot]</td>\n",
       "      <td>[Breonna, Taylor]</td>\n",
       "      <td>shot</td>\n",
       "      <td>Breonna Taylor</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>85293590</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>CBS News</td>\n",
       "      <td>([faulted], [Trump])</td>\n",
       "      <td>[faulted]</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>faulted</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>85294490</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>Reason</td>\n",
       "      <td>([blame], [Trump])</td>\n",
       "      <td>[blame]</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>blame</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>85295191</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>([criticized], [Trump])</td>\n",
       "      <td>[criticized]</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>criticized</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>85295191</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>([described], [Trumps])</td>\n",
       "      <td>[described]</td>\n",
       "      <td>[Trumps]</td>\n",
       "      <td>described</td>\n",
       "      <td>Trumps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>85295191</td>\n",
       "      <td>20-06-29</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>([led], [Trump])</td>\n",
       "      <td>[led]</td>\n",
       "      <td>[Trump]</td>\n",
       "      <td>led</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13499 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Date      News_source_name  \\\n",
       "0      31964104  20-07-18           vulture.com   \n",
       "1      31972010  20-07-23    washingtonpost.com   \n",
       "2      31874644  20-06-01             nymag.com   \n",
       "3      31882645  20-06-05  chicago.suntimes.com   \n",
       "4      31883040  20-06-05          euronews.com   \n",
       "...         ...       ...                   ...   \n",
       "13494  85293590  20-06-29              CBS News   \n",
       "13495  85294490  20-06-29                Reason   \n",
       "13496  85295191  20-06-29              The Hill   \n",
       "13497  85295191  20-06-29              The Hill   \n",
       "13498  85295191  20-06-29              The Hill   \n",
       "\n",
       "                                             VOs             V  \\\n",
       "0                ([mentions], [Breonna, Taylor])    [mentions]   \n",
       "1                ([murdered], [Breonna, Taylor])    [murdered]   \n",
       "2                  ([killed], [Breonna, Taylor])      [killed]   \n",
       "3      ([named], [[Breonna, Taylor], [Johnson]])       [named]   \n",
       "4                    ([shot], [Breonna, Taylor])        [shot]   \n",
       "...                                          ...           ...   \n",
       "13494                       ([faulted], [Trump])     [faulted]   \n",
       "13495                         ([blame], [Trump])       [blame]   \n",
       "13496                    ([criticized], [Trump])  [criticized]   \n",
       "13497                    ([described], [Trumps])   [described]   \n",
       "13498                           ([led], [Trump])         [led]   \n",
       "\n",
       "                                    O    V_string                    O_string  \\\n",
       "0                   [Breonna, Taylor]    mentions              Breonna Taylor   \n",
       "1                   [Breonna, Taylor]    murdered              Breonna Taylor   \n",
       "2                   [Breonna, Taylor]      killed              Breonna Taylor   \n",
       "3      [[Breonna, Taylor], [Johnson]]       named  [Breonna Taylor] [Johnson]   \n",
       "4                   [Breonna, Taylor]        shot              Breonna Taylor   \n",
       "...                               ...         ...                         ...   \n",
       "13494                         [Trump]     faulted                       Trump   \n",
       "13495                         [Trump]       blame                       Trump   \n",
       "13496                         [Trump]  criticized                       Trump   \n",
       "13497                        [Trumps]   described                      Trumps   \n",
       "13498                         [Trump]         led                       Trump   \n",
       "\n",
       "      Side  \n",
       "0       -1  \n",
       "1       -1  \n",
       "2       -1  \n",
       "3       -1  \n",
       "4       -1  \n",
       "...    ...  \n",
       "13494    1  \n",
       "13495    1  \n",
       "13496    1  \n",
       "13497    1  \n",
       "13498    1  \n",
       "\n",
       "[13499 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering to see how many BLM relevant Objects there are in VO df\n",
    "# adding a numeric code, representing the following: -1 = BLM side (against authority - liberal), 1 = anti-BLM side (for authority - conservative), 0 = shoudl trigger disapproval by both sides, e.g. Zimmerman, brutality, Chauvin\n",
    "\n",
    "VO_df_nona_breonna_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Breonna\", case = False)]\n",
    "VO_df_nona_breonna_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_floyd_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Floyd\", case = False)]\n",
    "VO_df_nona_floyd_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_trayvon_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Trayvon\", case = False)]\n",
    "VO_df_nona_trayvon_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_movement_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"movement\", case = False)]\n",
    "VO_df_nona_movement_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_blacklivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Black Lives Matter\", case = False)]\n",
    "VO_df_nona_blacklivesmatter_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_blm_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"BLM\", case = False)]\n",
    "VO_df_nona_blm_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_htblacklivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"#BlackLivesMatter\", case = False)]\n",
    "VO_df_nona_htblacklivesmatter_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_protester_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"protester\", case = False)]\n",
    "VO_df_nona_protester_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_demonstrator_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"demonstrator\", case = False)]\n",
    "VO_df_nona_demonstrator_O[\"Side\"] = \"-1\"\n",
    "VO_df_nona_nationalguard_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"National Guard\", case = False)]\n",
    "VO_df_nona_nationalguard_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_bluelivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"Blue Lives Matter\", case = False)]\n",
    "VO_df_nona_bluelivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_htbluelivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"#BlueLivesMatter\", case = False)]\n",
    "VO_df_nona_htbluelivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_alllivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"All Lives Matter\", case = False)]\n",
    "VO_df_nona_alllivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_htalllivesmatter_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"#AllLivesMatter\", case = False)]\n",
    "VO_df_nona_htalllivesmatter_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_police_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"police\", case = False)]\n",
    "VO_df_nona_police_O[\"Side\"] = \"1\"\n",
    "VO_df_nona_government_O = VO_df_nona[VO_df_nona['O_string'].str.contains(\"government\", case = False)]\n",
    "VO_df_nona_government_O[\"Side\"] = \"1\"\n",
    "\n",
    "VO_df_nona_terms = pd.concat([VO_df_nona_breonna_O,\n",
    "                               VO_df_nona_floyd_O,\n",
    "                               VO_df_nona_trayvon_O,\n",
    "                               VO_df_nona_movement_O,\n",
    "                               VO_df_nona_blacklivesmatter_O,\n",
    "                               VO_df_nona_blm_O,\n",
    "                               VO_df_nona_htblacklivesmatter_O,\n",
    "                               VO_df_nona_protester_O,\n",
    "                               VO_df_nona_demonstrator_O,\n",
    "                               VO_df_nona_nationalguard_O,\n",
    "                               VO_df_nona_bluelivesmatter_O,\n",
    "                               VO_df_nona_htbluelivesmatter_O,\n",
    "                               VO_df_nona_alllivesmatter_O,\n",
    "                               VO_df_nona_htalllivesmatter_O,\n",
    "                               VO_df_nona_police_O,\n",
    "                               VO_df_nona_government_O\n",
    "                              ],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "VO_df_nona_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6f6ff",
   "metadata": {},
   "source": [
    "## Lemmatizing the V columns to enable the merger with connotation score dataset, and to allow for later analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba600e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on filtered term list dfs from above\n",
    "# following this guide: https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "# import these modules\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_fun(verb):\n",
    "    verb_lemmatized = lemmatizer.lemmatize(verb, 'v')\n",
    "    return verb_lemmatized\n",
    "\n",
    "SV_df_nona_terms['V_lemmatized'] = SV_df_nona_terms.apply(lambda row: lemmatizer_fun(row[\"V_string\"]), axis = 1)\n",
    "VO_df_nona_terms['V_lemmatized'] = VO_df_nona_terms.apply(lambda row: lemmatizer_fun(row[\"V_string\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b86078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a287cf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85ba496",
   "metadata": {},
   "source": [
    "## Connotation dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd37aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>Perspective(wo)</th>\n",
       "      <th>Perspective(ws)</th>\n",
       "      <th>Perspective(so)</th>\n",
       "      <th>Effect(o)</th>\n",
       "      <th>Effect(s)</th>\n",
       "      <th>Value(o)</th>\n",
       "      <th>Value(s)</th>\n",
       "      <th>State(o)</th>\n",
       "      <th>State(s)</th>\n",
       "      <th>Perspective(ro)</th>\n",
       "      <th>Perspective(rs)</th>\n",
       "      <th>Perspective(os)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>breed</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>enrich</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>court</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>reconcile</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>displace</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          verb  Perspective(wo)  Perspective(ws)  Perspective(so)  Effect(o)  \\\n",
       "0         have         0.366667         0.333333         0.466667   0.066667   \n",
       "1          say         0.000000         0.166667         0.066667   0.133333   \n",
       "2         make        -0.066667         0.100000         0.100000   0.466667   \n",
       "3         take         0.500000         0.600000         0.800000   0.133333   \n",
       "4           go         0.066667         0.133333         0.200000   0.000000   \n",
       "..         ...              ...              ...              ...        ...   \n",
       "942      breed        -0.366667        -0.500000         0.000000   0.266667   \n",
       "943     enrich         0.566667         0.533333         0.300000   0.866667   \n",
       "944      court         0.266667         0.433333         0.366667   0.400000   \n",
       "945  reconcile         0.400000         0.566667         0.133333   0.533333   \n",
       "946   displace         0.133333        -0.233333        -0.133333  -0.666667   \n",
       "\n",
       "     Effect(s)  Value(o)  Value(s)  State(o)  State(s)  Perspective(ro)  \\\n",
       "0     0.200000  0.466667  0.600000  0.066667  0.366667         0.400000   \n",
       "1     0.066667  0.066667  1.000000  0.000000  0.100000         0.033333   \n",
       "2    -0.066667  0.200000  1.000000  0.000000  0.166667        -0.033333   \n",
       "3     0.600000  0.466667  0.600000  0.033333  0.666667         0.500000   \n",
       "4     0.066667 -0.066667  0.466667 -0.100000  0.033333         0.066667   \n",
       "..         ...       ...       ...       ...       ...              ...   \n",
       "942  -0.066667  0.066667  0.066667 -0.166667 -0.100000        -0.400000   \n",
       "943   0.266667  1.000000  0.600000  0.433333  0.400000         0.466667   \n",
       "944   0.400000  0.866667  1.000000  0.333333  0.466667         0.333333   \n",
       "945   0.333333  0.600000  0.466667  0.400000  0.033333         0.566667   \n",
       "946   0.200000  0.733333  0.066667 -0.733333 -0.033333         0.100000   \n",
       "\n",
       "     Perspective(rs)  Perspective(os)  \n",
       "0           0.366667         0.066667  \n",
       "1           0.266667         0.000000  \n",
       "2           0.200000         0.000000  \n",
       "3           0.566667         0.066667  \n",
       "4           0.066667        -0.100000  \n",
       "..               ...              ...  \n",
       "942        -0.500000         0.000000  \n",
       "943         0.433333         0.533333  \n",
       "944         0.366667         0.300000  \n",
       "945         0.600000         0.433333  \n",
       "946        -0.133333        -0.733333  \n",
       "\n",
       "[947 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connotation scores originating from this paper: https://aclanthology.org/P16-1030.pdf\n",
    "\n",
    "connotation_df = pd.read_csv(\"data/connotation_dataset/full_frame_info.txt\", sep='\\t')\n",
    "connotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d881ec07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>Perspective(wo)</th>\n",
       "      <th>Perspective(ws)</th>\n",
       "      <th>Perspective(so)</th>\n",
       "      <th>Effect(o)</th>\n",
       "      <th>Effect(s)</th>\n",
       "      <th>Value(o)</th>\n",
       "      <th>Value(s)</th>\n",
       "      <th>State(o)</th>\n",
       "      <th>State(s)</th>\n",
       "      <th>Perspective(ro)</th>\n",
       "      <th>Perspective(rs)</th>\n",
       "      <th>Perspective(os)</th>\n",
       "      <th>V_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>make</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>breed</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>breed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>enrich</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>enrich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>court</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>reconcile</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>reconcile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>displace</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>displace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          verb  Perspective(wo)  Perspective(ws)  Perspective(so)  Effect(o)  \\\n",
       "0         have         0.366667         0.333333         0.466667   0.066667   \n",
       "1          say         0.000000         0.166667         0.066667   0.133333   \n",
       "2         make        -0.066667         0.100000         0.100000   0.466667   \n",
       "3         take         0.500000         0.600000         0.800000   0.133333   \n",
       "4           go         0.066667         0.133333         0.200000   0.000000   \n",
       "..         ...              ...              ...              ...        ...   \n",
       "942      breed        -0.366667        -0.500000         0.000000   0.266667   \n",
       "943     enrich         0.566667         0.533333         0.300000   0.866667   \n",
       "944      court         0.266667         0.433333         0.366667   0.400000   \n",
       "945  reconcile         0.400000         0.566667         0.133333   0.533333   \n",
       "946   displace         0.133333        -0.233333        -0.133333  -0.666667   \n",
       "\n",
       "     Effect(s)  Value(o)  Value(s)  State(o)  State(s)  Perspective(ro)  \\\n",
       "0     0.200000  0.466667  0.600000  0.066667  0.366667         0.400000   \n",
       "1     0.066667  0.066667  1.000000  0.000000  0.100000         0.033333   \n",
       "2    -0.066667  0.200000  1.000000  0.000000  0.166667        -0.033333   \n",
       "3     0.600000  0.466667  0.600000  0.033333  0.666667         0.500000   \n",
       "4     0.066667 -0.066667  0.466667 -0.100000  0.033333         0.066667   \n",
       "..         ...       ...       ...       ...       ...              ...   \n",
       "942  -0.066667  0.066667  0.066667 -0.166667 -0.100000        -0.400000   \n",
       "943   0.266667  1.000000  0.600000  0.433333  0.400000         0.466667   \n",
       "944   0.400000  0.866667  1.000000  0.333333  0.466667         0.333333   \n",
       "945   0.333333  0.600000  0.466667  0.400000  0.033333         0.566667   \n",
       "946   0.200000  0.733333  0.066667 -0.733333 -0.033333         0.100000   \n",
       "\n",
       "     Perspective(rs)  Perspective(os) V_lemmatized  \n",
       "0           0.366667         0.066667         have  \n",
       "1           0.266667         0.000000          say  \n",
       "2           0.200000         0.000000         make  \n",
       "3           0.566667         0.066667         take  \n",
       "4           0.066667        -0.100000           go  \n",
       "..               ...              ...          ...  \n",
       "942        -0.500000         0.000000        breed  \n",
       "943         0.433333         0.533333       enrich  \n",
       "944         0.366667         0.300000        court  \n",
       "945         0.600000         0.433333    reconcile  \n",
       "946        -0.133333        -0.733333     displace  \n",
       "\n",
       "[947 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatizing connotation score df to make sure it can be matched to the SV, VO dataframes by verb\n",
    "\n",
    "# following this guide: https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "# import these modules\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_fun(verb):\n",
    "    verb_lemmatized = lemmatizer.lemmatize(verb, 'v')\n",
    "    return verb_lemmatized\n",
    "\n",
    "connotation_df['V_lemmatized'] = connotation_df.apply(lambda row: lemmatizer_fun(row[\"verb\"]), axis = 1)\n",
    "\n",
    "connotation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0087ae32",
   "metadata": {},
   "source": [
    "## Merging filtered SV, VO dfs with connotation frame scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e33213d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# running on filtered term list dfs from above\n",
    "\n",
    "SV_df_nona_terms_connotation = SV_df_nona_terms.merge(connotation_df, on = 'V_lemmatized', how = 'left')\n",
    "\n",
    "VO_df_nona_terms_connotation = VO_df_nona_terms.merge(connotation_df, on = 'V_lemmatized', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2064259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7381\n",
      "2379\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# running on filtered term list dfs from above\n",
    "\n",
    "# removing rows that have no connotation rating for the verb\n",
    "\n",
    "print(SV_df_nona_terms_connotation.verb.isna().sum())\n",
    "print(VO_df_nona_terms_connotation.verb.isna().sum())\n",
    "\n",
    "term_list_df_SV_connotation_nonaverb = SV_df_nona_terms_connotation[SV_df_nona_terms_connotation['verb'].notna()]\n",
    "term_list_df_VO_connotation_nonaverb = VO_df_nona_terms_connotation[VO_df_nona_terms_connotation['verb'].notna()]\n",
    "\n",
    "print(term_list_df_SV_connotation_nonaverb.verb.isna().sum())\n",
    "print(term_list_df_VO_connotation_nonaverb.verb.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda91e1",
   "metadata": {},
   "source": [
    "## News media bias sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f8be8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_in_NOW_data</th>\n",
       "      <th>name_in_allsides_data</th>\n",
       "      <th>media_bias_rating</th>\n",
       "      <th>accessed</th>\n",
       "      <th>column</th>\n",
       "      <th>url</th>\n",
       "      <th>url_allsides</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Axios</td>\n",
       "      <td>Axios</td>\n",
       "      <td>Center</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.axios.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/axios</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barron's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Center</td>\n",
       "      <td>Ad Fontes Media Bias Chart 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Center</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>allsides</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Insider on MSN.com</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Center</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>allsides</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>businessinsider.com</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Center</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>allsides</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>The Raw Story</td>\n",
       "      <td>Raw Story</td>\n",
       "      <td>Left</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.rawstory.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/raw-story</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Fox News</td>\n",
       "      <td>Fox News (Online News)</td>\n",
       "      <td>Right</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.foxnews.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/fox-news-...</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>foxnews.com</td>\n",
       "      <td>Fox News (Online News)</td>\n",
       "      <td>Right</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.foxnews.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/fox-news-...</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ksl.com</td>\n",
       "      <td>KSL</td>\n",
       "      <td>Right</td>\n",
       "      <td>from AllSides December 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.ksl.com/</td>\n",
       "      <td>https://www.allsides.com/news-source/ksl</td>\n",
       "      <td>News Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>LifeSiteNews</td>\n",
       "      <td>Life Site News</td>\n",
       "      <td>Right</td>\n",
       "      <td>from supervisor 2019</td>\n",
       "      <td>media_bias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name_in_NOW_data   name_in_allsides_data media_bias_rating  \\\n",
       "0                          Axios                   Axios            Center   \n",
       "1                       Barron's                     NaN            Center   \n",
       "2               Business Insider        Business Insider            Center   \n",
       "3    Business Insider on MSN.com        Business Insider            Center   \n",
       "4            businessinsider.com        Business Insider            Center   \n",
       "..                           ...                     ...               ...   \n",
       "160                The Raw Story               Raw Story              Left   \n",
       "161                     Fox News  Fox News (Online News)             Right   \n",
       "162                  foxnews.com  Fox News (Online News)             Right   \n",
       "163                      ksl.com                     KSL             Right   \n",
       "164                 LifeSiteNews          Life Site News             Right   \n",
       "\n",
       "                            accessed      column                       url  \\\n",
       "0        from AllSides December 2021         NaN    https://www.axios.com/   \n",
       "1    Ad Fontes Media Bias Chart 2021         NaN                       NaN   \n",
       "2               from supervisor 2019    allsides                       NaN   \n",
       "3               from supervisor 2019    allsides                       NaN   \n",
       "4               from supervisor 2019    allsides                       NaN   \n",
       "..                               ...         ...                       ...   \n",
       "160      from AllSides December 2021         NaN  http://www.rawstory.com/   \n",
       "161      from AllSides December 2021         NaN   http://www.foxnews.com/   \n",
       "162      from AllSides December 2021         NaN   http://www.foxnews.com/   \n",
       "163      from AllSides December 2021         NaN       http://www.ksl.com/   \n",
       "164             from supervisor 2019  media_bias                       NaN   \n",
       "\n",
       "                                          url_allsides    category  \n",
       "0           https://www.allsides.com/news-source/axios  News Media  \n",
       "1                                                  NaN         NaN  \n",
       "2                                                  NaN         NaN  \n",
       "3                                                  NaN         NaN  \n",
       "4                                                  NaN         NaN  \n",
       "..                                                 ...         ...  \n",
       "160     https://www.allsides.com/news-source/raw-story  News Media  \n",
       "161  https://www.allsides.com/news-source/fox-news-...  News Media  \n",
       "162  https://www.allsides.com/news-source/fox-news-...  News Media  \n",
       "163           https://www.allsides.com/news-source/ksl  News Media  \n",
       "164                                                NaN         NaN  \n",
       "\n",
       "[165 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in media bias df\n",
    "\n",
    "media_bias_df = pd.read_csv(\"data/news_political_alignment_ratings/news_sources_matching_bestversion.csv\", sep = ';')\n",
    "\n",
    "media_bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae249c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# renaming SV, VO dfs news source column to enable left join merger\n",
    "\n",
    "term_list_df_SV_connotation_nonaverb = term_list_df_SV_connotation_nonaverb.rename(columns={'News_source_name': 'name_in_NOW_data'})\n",
    "term_list_df_VO_connotation_nonaverb = term_list_df_VO_connotation_nonaverb.rename(columns={'News_source_name': 'name_in_NOW_data'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33787086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# left joining media bias df to the SV, VO dataframes\n",
    "\n",
    "SV_connotation_bias_df = term_list_df_SV_connotation_nonaverb.merge(media_bias_df, on = 'name_in_NOW_data', how = 'left')\n",
    "VO_connotation_bias_df = term_list_df_VO_connotation_nonaverb.merge(media_bias_df, on = 'name_in_NOW_data', how = 'left')\n",
    "\n",
    "SV_connotation_bias_df.to_csv(\"data/NOW_preprocessed/SV_BLM_bias_connotation_combined.csv\", index = False)\n",
    "VO_connotation_bias_df.to_csv(\"data/NOW_preprocessed/VO_BLM_bias_connotation_combined.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b7591",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
